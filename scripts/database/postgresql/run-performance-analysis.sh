#!/bin/bash

# =============================================================================
# PostgreSQL ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æçµ±åˆå®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ
# =============================================================================

set -euo pipefail

# è¨­å®š
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(cd "${SCRIPT_DIR}/.." && pwd)"
CONTAINER_NAME="monstera-postgres-test"
DB_HOST="${DB_HOST:-localhost}"
DB_PORT="${DB_PORT:-5432}"
DB_NAME="${DB_NAME:-monstera_test}"
DB_USER="${DB_USER:-monstera}"
DB_PASSWORD="${DB_PASSWORD:-password}"

# çµæœä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
RESULTS_DIR="${PROJECT_ROOT}/performance-analysis-results"
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")

# è‰²ä»˜ããƒ­ã‚°å‡ºåŠ›
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# å‰ææ¡ä»¶ãƒã‚§ãƒƒã‚¯
check_prerequisites() {
    log_info "å‰ææ¡ä»¶ãƒã‚§ãƒƒã‚¯..."
    
    # PostgreSQLæ¥ç¶šç¢ºèª
    if ! docker exec "${CONTAINER_NAME}" pg_isready -U "${DB_USER}" -d "${DB_NAME}" > /dev/null 2>&1; then
        log_error "PostgreSQLã«æ¥ç¶šã§ãã¾ã›ã‚“"
        log_info "ã‚³ãƒ³ãƒ†ãƒŠã‚’èµ·å‹•ã—ã¦ãã ã•ã„: ./scripts/postgresql-container-manager.sh start"
        return 1
    fi
    
    # å¿…è¦ãªã‚³ãƒãƒ³ãƒ‰ç¢ºèª
    local missing_commands=()
    
    if ! command -v jq &> /dev/null; then
        missing_commands+=("jq")
    fi
    
    if ! command -v go &> /dev/null; then
        missing_commands+=("go")
    fi
    
    if [ ${#missing_commands[@]} -gt 0 ]; then
        log_warning "ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: ${missing_commands[*]}"
        log_info "ä¸€éƒ¨ã®åˆ†ææ©Ÿèƒ½ãŒåˆ¶é™ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™"
    fi
    
    log_success "å‰ææ¡ä»¶ãƒã‚§ãƒƒã‚¯å®Œäº†"
}

# çµæœãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
create_results_dir() {
    if [ ! -d "${RESULTS_DIR}" ]; then
        mkdir -p "${RESULTS_DIR}"
        log_info "çµæœãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ: ${RESULTS_DIR}"
    fi
    
    # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    ANALYSIS_DIR="${RESULTS_DIR}/analysis_${TIMESTAMP}"
    mkdir -p "${ANALYSIS_DIR}"
    log_info "åˆ†æçµæœãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: ${ANALYSIS_DIR}"
}

# åŸºæœ¬çµ±è¨ˆæƒ…å ±åé›†
collect_basic_stats() {
    log_info "åŸºæœ¬çµ±è¨ˆæƒ…å ±åé›†..."
    
    local stats_file="${ANALYSIS_DIR}/basic_stats.txt"
    
    {
        echo "=== PostgreSQLåŸºæœ¬çµ±è¨ˆæƒ…å ± ==="
        echo "åé›†æ—¥æ™‚: $(date)"
        echo ""
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æƒ…å ±
        echo "--- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æƒ…å ± ---"
        docker exec "${CONTAINER_NAME}" psql -U "${DB_USER}" -d "${DB_NAME}" -c "
            SELECT 
                current_database() as database,
                version() as version,
                pg_size_pretty(pg_database_size(current_database())) as size;
        "
        
        echo ""
        echo "--- æ¥ç¶šæƒ…å ± ---"
        docker exec "${CONTAINER_NAME}" psql -U "${DB_USER}" -d "${DB_NAME}" -c "
            SELECT 
                state,
                COUNT(*) as count
            FROM pg_stat_activity 
            WHERE datname = current_database()
            GROUP BY state;
        "
        
        echo ""
        echo "--- ãƒ†ãƒ¼ãƒ–ãƒ«æ•° ---"
        docker exec "${CONTAINER_NAME}" psql -U "${DB_USER}" -d "${DB_NAME}" -c "
            SELECT COUNT(*) as table_count FROM pg_tables WHERE schemaname = 'public';
        "
        
        echo ""
        echo "--- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ•° ---"
        docker exec "${CONTAINER_NAME}" psql -U "${DB_USER}" -d "${DB_NAME}" -c "
            SELECT COUNT(*) as index_count FROM pg_indexes WHERE schemaname = 'public';
        "
        
    } > "${stats_file}"
    
    log_success "åŸºæœ¬çµ±è¨ˆæƒ…å ±ã‚’ä¿å­˜: ${stats_file}"
}

# ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ãƒ¬ãƒãƒ¼ãƒˆå®Ÿè¡Œ
run_performance_monitor() {
    log_info "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ãƒ¬ãƒãƒ¼ãƒˆå®Ÿè¡Œ..."
    
    local monitor_file="${ANALYSIS_DIR}/performance_monitor_report.txt"
    
    # PostgreSQLç›£è¦–ã‚¯ã‚¨ãƒªå®Ÿè¡Œ
    docker exec -i "${CONTAINER_NAME}" psql -U "${DB_USER}" -d "${DB_NAME}" < "${SCRIPT_DIR}/postgresql-performance-monitor.sql" > "${monitor_file}" 2>&1
    
    log_success "ç›£è¦–ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜: ${monitor_file}"
}

# EXPLAIN ANALYZEåˆ†æå®Ÿè¡Œ
run_explain_analyze() {
    log_info "EXPLAIN ANALYZEåˆ†æå®Ÿè¡Œ..."
    
    # ã‚·ã‚§ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆç‰ˆEXPLAIN ANALYZEå®Ÿè¡Œ
    "${SCRIPT_DIR}/explain-analyze-performance-test.sh" full
    
    # çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†æãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç§»å‹•
    local latest_explain_file=$(ls -t "${PROJECT_ROOT}/performance-test-results"/explain_analyze_*.md 2>/dev/null | head -1 || echo "")
    
    if [ -n "${latest_explain_file}" ] && [ -f "${latest_explain_file}" ]; then
        cp "${latest_explain_file}" "${ANALYSIS_DIR}/explain_analyze_report.md"
        log_success "EXPLAIN ANALYZEçµæœã‚’ã‚³ãƒ”ãƒ¼: ${ANALYSIS_DIR}/explain_analyze_report.md"
    else
        log_warning "EXPLAIN ANALYZEçµæœãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
    fi
}

# Goç‰ˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æå®Ÿè¡Œ
run_go_analyzer() {
    log_info "Goç‰ˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æå®Ÿè¡Œ..."
    
    # ç’°å¢ƒå¤‰æ•°è¨­å®š
    export DB_HOST="${DB_HOST}"
    export DB_PORT="${DB_PORT}"
    export DB_NAME="${DB_NAME}"
    export DB_USER="${DB_USER}"
    export DB_PASSWORD="${DB_PASSWORD}"
    export DB_SSL_MODE="disable"
    
    # Goåˆ†æå™¨å®Ÿè¡Œ
    cd "${SCRIPT_DIR}"
    
    if command -v go &> /dev/null; then
        # Goä¾å­˜é–¢ä¿‚å–å¾—
        if [ ! -f "go.mod" ]; then
            go mod init query-performance-analyzer
            go mod tidy
        fi
        
        # PostgreSQLãƒ‰ãƒ©ã‚¤ãƒãƒ¼è¿½åŠ 
        go get github.com/lib/pq
        
        # åˆ†æå®Ÿè¡Œ
        if go run query-performance-analyzer.go; then
            # çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç§»å‹•
            for file in query_performance_*.json query_performance_*.md; do
                if [ -f "${file}" ]; then
                    mv "${file}" "${ANALYSIS_DIR}/"
                    log_success "Goåˆ†æçµæœã‚’ç§»å‹•: ${file}"
                fi
            done
        else
            log_warning "Goç‰ˆåˆ†æå™¨ã®å®Ÿè¡Œã«å¤±æ•—ã—ã¾ã—ãŸ"
        fi
    else
        log_warning "Goã‚³ãƒãƒ³ãƒ‰ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€Goç‰ˆåˆ†æå™¨ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™"
    fi
    
    cd "${PROJECT_ROOT}"
}

# ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½¿ç”¨çŠ¶æ³åˆ†æ
analyze_index_usage() {
    log_info "ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½¿ç”¨çŠ¶æ³åˆ†æ..."
    
    local index_file="${ANALYSIS_DIR}/index_usage_analysis.txt"
    
    {
        echo "=== ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½¿ç”¨çŠ¶æ³åˆ†æ ==="
        echo "åˆ†ææ—¥æ™‚: $(date)"
        echo ""
        
        echo "--- æœ€ã‚‚ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ TOP 10 ---"
        docker exec "${CONTAINER_NAME}" psql -U "${DB_USER}" -d "${DB_NAME}" -c "
            SELECT 
                schemaname,
                tablename,
                indexname,
                idx_scan as scans,
                idx_tup_read as tuples_read,
                pg_size_pretty(pg_relation_size(indexrelname::regclass)) as size
            FROM pg_stat_user_indexes
            ORDER BY idx_scan DESC
            LIMIT 10;
        "
        
        echo ""
        echo "--- æœªä½¿ç”¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ ---"
        docker exec "${CONTAINER_NAME}" psql -U "${DB_USER}" -d "${DB_NAME}" -c "
            SELECT 
                schemaname,
                tablename,
                indexname,
                pg_size_pretty(pg_relation_size(indexrelname::regclass)) as wasted_size
            FROM pg_stat_user_indexes
            WHERE idx_scan = 0
                AND indexrelname NOT LIKE '%_pkey'
            ORDER BY pg_relation_size(indexrelname::regclass) DESC;
        "
        
        echo ""
        echo "--- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚µã‚¤ã‚º TOP 10 ---"
        docker exec "${CONTAINER_NAME}" psql -U "${DB_USER}" -d "${DB_NAME}" -c "
            SELECT 
                schemaname,
                tablename,
                indexname,
                pg_size_pretty(pg_relation_size(indexrelname::regclass)) as size,
                idx_scan as scans
            FROM pg_stat_user_indexes
            ORDER BY pg_relation_size(indexrelname::regclass) DESC
            LIMIT 10;
        "
        
    } > "${index_file}"
    
    log_success "ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åˆ†æã‚’ä¿å­˜: ${index_file}"
}

# ã‚¹ãƒ­ãƒ¼ã‚¯ã‚¨ãƒªåˆ†æ
analyze_slow_queries() {
    log_info "ã‚¹ãƒ­ãƒ¼ã‚¯ã‚¨ãƒªåˆ†æ..."
    
    local slow_query_file="${ANALYSIS_DIR}/slow_query_analysis.txt"
    
    {
        echo "=== ã‚¹ãƒ­ãƒ¼ã‚¯ã‚¨ãƒªåˆ†æ ==="
        echo "åˆ†ææ—¥æ™‚: $(date)"
        echo ""
        
        echo "--- ç¾åœ¨å®Ÿè¡Œä¸­ã®é•·æ™‚é–“ã‚¯ã‚¨ãƒª ---"
        docker exec "${CONTAINER_NAME}" psql -U "${DB_USER}" -d "${DB_NAME}" -c "
            SELECT 
                pid,
                usename,
                state,
                ROUND(EXTRACT(EPOCH FROM (now() - query_start))::numeric, 2) as duration_seconds,
                LEFT(query, 100) as query_preview
            FROM pg_stat_activity
            WHERE datname = current_database()
                AND state = 'active'
                AND query_start < now() - INTERVAL '5 seconds'
            ORDER BY duration_seconds DESC;
        "
        
        echo ""
        echo "--- pg_stat_statementsæƒ…å ±ï¼ˆæœ‰åŠ¹ãªå ´åˆï¼‰ ---"
        # pg_stat_statementsãŒæœ‰åŠ¹ã‹ãƒã‚§ãƒƒã‚¯
        if docker exec "${CONTAINER_NAME}" psql -U "${DB_USER}" -d "${DB_NAME}" -c "SELECT 1 FROM pg_extension WHERE extname = 'pg_stat_statements';" 2>/dev/null | grep -q "1"; then
            docker exec "${CONTAINER_NAME}" psql -U "${DB_USER}" -d "${DB_NAME}" -c "
                SELECT 
                    calls,
                    ROUND(total_exec_time::numeric, 2) as total_time_ms,
                    ROUND(mean_exec_time::numeric, 2) as avg_time_ms,
                    ROUND(max_exec_time::numeric, 2) as max_time_ms,
                    LEFT(query, 100) as query_preview
                FROM pg_stat_statements
                ORDER BY total_exec_time DESC
                LIMIT 10;
            "
        else
            echo "pg_stat_statementsæ‹¡å¼µãŒç„¡åŠ¹ã§ã™"
        fi
        
    } > "${slow_query_file}"
    
    log_success "ã‚¹ãƒ­ãƒ¼ã‚¯ã‚¨ãƒªåˆ†æã‚’ä¿å­˜: ${slow_query_file}"
}

# ãƒ†ãƒ¼ãƒ–ãƒ«çµ±è¨ˆæƒ…å ±åˆ†æ
analyze_table_stats() {
    log_info "ãƒ†ãƒ¼ãƒ–ãƒ«çµ±è¨ˆæƒ…å ±åˆ†æ..."
    
    local table_stats_file="${ANALYSIS_DIR}/table_statistics.txt"
    
    {
        echo "=== ãƒ†ãƒ¼ãƒ–ãƒ«çµ±è¨ˆæƒ…å ±åˆ†æ ==="
        echo "åˆ†ææ—¥æ™‚: $(date)"
        echo ""
        
        echo "--- ãƒ†ãƒ¼ãƒ–ãƒ«ã‚µã‚¤ã‚º TOP 10 ---"
        docker exec "${CONTAINER_NAME}" psql -U "${DB_USER}" -d "${DB_NAME}" -c "
            SELECT 
                schemaname,
                tablename,
                pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as total_size,
                pg_size_pretty(pg_relation_size(schemaname||'.'||tablename)) as table_size,
                pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename) - pg_relation_size(schemaname||'.'||tablename)) as index_size
            FROM pg_tables
            WHERE schemaname = 'public'
            ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC
            LIMIT 10;
        "
        
        echo ""
        echo "--- æ›´æ–°é »åº¦ã®é«˜ã„ãƒ†ãƒ¼ãƒ–ãƒ« ---"
        docker exec "${CONTAINER_NAME}" psql -U "${DB_USER}" -d "${DB_NAME}" -c "
            SELECT 
                schemaname,
                tablename,
                n_tup_ins as inserts,
                n_tup_upd as updates,
                n_tup_del as deletes,
                n_live_tup as live_tuples,
                n_dead_tup as dead_tuples,
                ROUND(100.0 * n_dead_tup / NULLIF(n_live_tup + n_dead_tup, 0), 2) as dead_tuple_ratio
            FROM pg_stat_user_tables
            WHERE n_tup_upd + n_tup_del > 0
            ORDER BY n_tup_upd + n_tup_del DESC
            LIMIT 10;
        "
        
        echo ""
        echo "--- VACUUM/ANALYZEå®Ÿè¡Œå±¥æ­´ ---"
        docker exec "${CONTAINER_NAME}" psql -U "${DB_USER}" -d "${DB_NAME}" -c "
            SELECT 
                schemaname,
                tablename,
                last_vacuum,
                last_autovacuum,
                last_analyze,
                last_autoanalyze,
                vacuum_count,
                autovacuum_count,
                analyze_count,
                autoanalyze_count
            FROM pg_stat_user_tables
            ORDER BY COALESCE(last_analyze, last_autoanalyze, '1970-01-01'::timestamp) ASC;
        "
        
    } > "${table_stats_file}"
    
    log_success "ãƒ†ãƒ¼ãƒ–ãƒ«çµ±è¨ˆæƒ…å ±ã‚’ä¿å­˜: ${table_stats_file}"
}

# æœ€é©åŒ–æ¨å¥¨äº‹é …ç”Ÿæˆ
generate_optimization_recommendations() {
    log_info "æœ€é©åŒ–æ¨å¥¨äº‹é …ç”Ÿæˆ..."
    
    local recommendations_file="${ANALYSIS_DIR}/optimization_recommendations.md"
    
    cat > "${recommendations_file}" << 'EOF'
# PostgreSQL æœ€é©åŒ–æ¨å¥¨äº‹é …

## æ¦‚è¦

ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã¯è‡ªå‹•åˆ†æã«åŸºã¥ãæœ€é©åŒ–æ¨å¥¨äº‹é …ã§ã™ã€‚

## ç·Šæ€¥å¯¾å¿œãŒå¿…è¦ãªé …ç›®

### 1. æœªä½¿ç”¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®å‰Šé™¤

ä»¥ä¸‹ã®ã‚¯ã‚¨ãƒªã§æœªä½¿ç”¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ç¢ºèªã—ã€ä¸è¦ãªã‚‚ã®ã¯å‰Šé™¤ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ï¼š

```sql
SELECT 
    schemaname,
    tablename,
    indexname,
    pg_size_pretty(pg_relation_size(indexrelname::regclass)) as wasted_size
FROM pg_stat_user_indexes
WHERE idx_scan = 0
    AND indexrelname NOT LIKE '%_pkey'
ORDER BY pg_relation_size(indexrelname::regclass) DESC;
```

### 2. ãƒ‡ãƒƒãƒ‰ã‚¿ãƒ—ãƒ«ã®å¤šã„ãƒ†ãƒ¼ãƒ–ãƒ«

ä»¥ä¸‹ã®ã‚¯ã‚¨ãƒªã§VACUUMãŒå¿…è¦ãªãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼š

```sql
SELECT 
    schemaname,
    tablename,
    n_dead_tup,
    ROUND(100.0 * n_dead_tup / NULLIF(n_live_tup + n_dead_tup, 0), 2) as dead_ratio
FROM pg_stat_user_tables
WHERE n_dead_tup > 1000
    AND 100.0 * n_dead_tup / NULLIF(n_live_tup + n_dead_tup, 0) > 10
ORDER BY dead_ratio DESC;
```

### 3. çµ±è¨ˆæƒ…å ±ã®æ›´æ–°

å¤ã„çµ±è¨ˆæƒ…å ±ã‚’æŒã¤ãƒ†ãƒ¼ãƒ–ãƒ«ã«ANALYZEã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ï¼š

```sql
-- å…¨ãƒ†ãƒ¼ãƒ–ãƒ«ã®çµ±è¨ˆæƒ…å ±æ›´æ–°
ANALYZE;

-- ç‰¹å®šãƒ†ãƒ¼ãƒ–ãƒ«ã®æ›´æ–°ä¾‹
-- ANALYZE table_name;
```

## å®šæœŸãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹é …ç›®

### 1. æ—¥æ¬¡ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹

```sql
-- è»½é‡ãªVACUUMï¼ˆæ¯æ—¥å®Ÿè¡Œæ¨å¥¨ï¼‰
VACUUM (VERBOSE, ANALYZE);
```

### 2. é€±æ¬¡ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹

```sql
-- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å†æ§‹ç¯‰ï¼ˆé€±1å›æ¨å¥¨ï¼‰
REINDEX DATABASE CONCURRENTLY your_database_name;
```

### 3. æœˆæ¬¡ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹

```sql
-- ãƒ•ãƒ«VACUUMï¼ˆæœˆ1å›æ¨å¥¨ã€ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹æ™‚é–“ä¸­ï¼‰
VACUUM (FULL, VERBOSE, ANALYZE);
```

## ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨­å®šæ¨å¥¨äº‹é …

### 1. PostgreSQLè¨­å®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

```sql
-- å…±æœ‰ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚ºï¼ˆç‰©ç†ãƒ¡ãƒ¢ãƒªã®25%ç¨‹åº¦ï¼‰
ALTER SYSTEM SET shared_buffers = '256MB';

-- ãƒ¯ãƒ¼ã‚¯ãƒ¡ãƒ¢ãƒªï¼ˆæ¥ç¶šæ•°ã‚’è€ƒæ…®ã—ã¦è¨­å®šï¼‰
ALTER SYSTEM SET work_mem = '16MB';

-- ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ç”¨ãƒ¯ãƒ¼ã‚¯ãƒ¡ãƒ¢ãƒª
ALTER SYSTEM SET maintenance_work_mem = '64MB';

-- å®ŸåŠ¹ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºï¼ˆç‰©ç†ãƒ¡ãƒ¢ãƒªã®75%ç¨‹åº¦ï¼‰
ALTER SYSTEM SET effective_cache_size = '1GB';

-- è¨­å®šåæ˜ 
SELECT pg_reload_conf();
```

### 2. ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æˆ¦ç•¥

#### æ¨å¥¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹

```sql
-- åŸºæœ¬çš„ãªæ¤œç´¢ã‚«ãƒ©ãƒ 
CREATE INDEX CONCURRENTLY idx_users_email ON users(email);
CREATE INDEX CONCURRENTLY idx_users_active ON users(is_active) WHERE is_active = true;

-- è¤‡åˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
CREATE INDEX CONCURRENTLY idx_weekly_reports_user_date ON weekly_reports(user_id, start_date);
CREATE INDEX CONCURRENTLY idx_engineer_proposals_status_created ON engineer_proposals(status, created_at);

-- éƒ¨åˆ†ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
CREATE INDEX CONCURRENTLY idx_weekly_reports_submitted ON weekly_reports(user_id, start_date) 
WHERE status IN ('submitted', 'approved');
```

#### GINã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆå…¨æ–‡æ¤œç´¢ç”¨ï¼‰

```sql
-- ãƒ†ã‚­ã‚¹ãƒˆæ¤œç´¢ç”¨
CREATE INDEX CONCURRENTLY idx_weekly_reports_remarks_gin ON weekly_reports 
USING gin(to_tsvector('english', weekly_remarks));
```

## ç›£è¦–è¨­å®šæ¨å¥¨äº‹é …

### 1. ã‚¹ãƒ­ãƒ¼ã‚¯ã‚¨ãƒªãƒ­ã‚°è¨­å®š

```sql
-- 1ç§’ä»¥ä¸Šã®ã‚¯ã‚¨ãƒªã‚’ãƒ­ã‚°ã«è¨˜éŒ²
ALTER SYSTEM SET log_min_duration_statement = 1000;

-- ãã®ä»–ã®æœ‰ç”¨ãªãƒ­ã‚°è¨­å®š
ALTER SYSTEM SET log_checkpoints = on;
ALTER SYSTEM SET log_lock_waits = on;
ALTER SYSTEM SET log_temp_files = 0;

-- è¨­å®šåæ˜ 
SELECT pg_reload_conf();
```

### 2. çµ±è¨ˆæ‹¡å¼µã®æœ‰åŠ¹åŒ–

```sql
-- pg_stat_statementsæ‹¡å¼µï¼ˆã‚¯ã‚¨ãƒªçµ±è¨ˆç”¨ï¼‰
CREATE EXTENSION IF NOT EXISTS pg_stat_statements;

-- auto_explainæ‹¡å¼µï¼ˆè‡ªå‹•å®Ÿè¡Œè¨ˆç”»ãƒ­ã‚°ï¼‰
-- postgresql.conf ã«ä»¥ä¸‹ã‚’è¿½åŠ :
-- shared_preload_libraries = 'auto_explain'
-- auto_explain.log_min_duration = 1000
```

## ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å´ã®æ¨å¥¨äº‹é …

### 1. ã‚¯ã‚¨ãƒªæœ€é©åŒ–

- **LIMITå¥ã®ä½¿ç”¨**: å¤§é‡ãƒ‡ãƒ¼ã‚¿ã‚’æ‰±ã†å ´åˆã¯å¿…ãšLIMITã‚’è¨­å®š
- **é©åˆ‡ãªã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åˆ©ç”¨**: WHEREå¥ã«ä½¿ç”¨ã™ã‚‹ã‚«ãƒ©ãƒ ã«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆ
- **JOINé †åºã®æœ€é©åŒ–**: å°ã•ã„ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰å¤§ãã„ãƒ†ãƒ¼ãƒ–ãƒ«ã¸JOIN

### 2. æ¥ç¶šãƒ—ãƒ¼ãƒ«è¨­å®š

- **max_connections**: PostgreSQLå´ã®æœ€å¤§æ¥ç¶šæ•°èª¿æ•´
- **connection pooling**: ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å´ã§ã‚³ãƒã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ¼ãƒ«å®Ÿè£…

### 3. ã‚­ãƒ£ãƒƒã‚·ãƒ¥æˆ¦ç•¥

- **ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¬ãƒ™ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥**: é »ç¹ã«ã‚¢ã‚¯ã‚»ã‚¹ã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥
- **ã‚¯ã‚¨ãƒªçµæœã‚­ãƒ£ãƒƒã‚·ãƒ¥**: é‡ã„ã‚¯ã‚¨ãƒªã®çµæœã‚­ãƒ£ãƒƒã‚·ãƒ¥

## æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

1. **ç·Šæ€¥å¯¾å¿œé …ç›®**ã®å®Ÿæ–½ï¼ˆæœªä½¿ç”¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å‰Šé™¤ã€VACUUMå®Ÿè¡Œï¼‰
2. **å®šæœŸãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹**ã®è‡ªå‹•åŒ–è¨­å®š
3. **ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ **ã®å°å…¥ãƒ»è¨­å®š
4. **1ãƒ¶æœˆå¾Œã®å†è©•ä¾¡**ã§åŠ¹æœæ¸¬å®š

## å‚è€ƒè³‡æ–™

- [PostgreSQL Performance Tuning](https://wiki.postgresql.org/wiki/Performance_Optimization)
- [EXPLAIN Documentation](https://www.postgresql.org/docs/current/using-explain.html)
- [PostgreSQL Monitoring](https://www.postgresql.org/docs/current/monitoring.html)
EOF
    
    log_success "æœ€é©åŒ–æ¨å¥¨äº‹é …ã‚’ä¿å­˜: ${recommendations_file}"
}

# ç·åˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
generate_comprehensive_report() {
    log_info "ç·åˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ..."
    
    local report_file="${ANALYSIS_DIR}/comprehensive_performance_report.md"
    
    cat > "${report_file}" << EOF
# PostgreSQL ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æç·åˆãƒ¬ãƒãƒ¼ãƒˆ

**åˆ†æå®Ÿè¡Œæ—¥æ™‚**: $(date '+%Y-%m-%d %H:%M:%S')
**ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹**: ${DB_NAME}
**åˆ†æãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª**: ${ANALYSIS_DIR}

## ãƒ¬ãƒãƒ¼ãƒˆæ¦‚è¦

ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã¯ã€PostgreSQLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®åŒ…æ‹¬çš„ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æçµæœã§ã™ã€‚

## åˆ†æå†…å®¹

### 1. åŸºæœ¬çµ±è¨ˆæƒ…å ±
- ãƒ•ã‚¡ã‚¤ãƒ«: \`basic_stats.txt\`
- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚µã‚¤ã‚ºã€æ¥ç¶šæ•°ã€ãƒ†ãƒ¼ãƒ–ãƒ«æ•°ãªã©ã®åŸºæœ¬æƒ…å ±

### 2. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ãƒ¬ãƒãƒ¼ãƒˆ
- ãƒ•ã‚¡ã‚¤ãƒ«: \`performance_monitor_report.txt\`
- è©³ç´°ãªçµ±è¨ˆæƒ…å ±ã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½¿ç”¨çŠ¶æ³ã€ãƒãƒƒãƒ•ã‚¡ã‚­ãƒ£ãƒƒã‚·ãƒ¥æƒ…å ±

### 3. EXPLAIN ANALYZEåˆ†æ
- ãƒ•ã‚¡ã‚¤ãƒ«: \`explain_analyze_report.md\`
- å®Ÿéš›ã®ã‚¯ã‚¨ãƒªå®Ÿè¡Œè¨ˆç”»ã¨æ€§èƒ½æ¸¬å®šçµæœ

### 4. Goç‰ˆè©³ç´°åˆ†æ
- ãƒ•ã‚¡ã‚¤ãƒ«: \`query_performance_*.json\`, \`query_performance_*.md\`
- æ§‹é€ åŒ–ã•ã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æã¨JSONå½¢å¼ã®è©³ç´°ãƒ‡ãƒ¼ã‚¿

### 5. ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½¿ç”¨çŠ¶æ³åˆ†æ
- ãƒ•ã‚¡ã‚¤ãƒ«: \`index_usage_analysis.txt\`
- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ä½¿ç”¨é »åº¦ã¨æœ€é©åŒ–å¯èƒ½æ€§

### 6. ã‚¹ãƒ­ãƒ¼ã‚¯ã‚¨ãƒªåˆ†æ
- ãƒ•ã‚¡ã‚¤ãƒ«: \`slow_query_analysis.txt\`
- å®Ÿè¡Œæ™‚é–“ã®é•·ã„ã‚¯ã‚¨ãƒªã®ç‰¹å®šã¨åˆ†æ

### 7. ãƒ†ãƒ¼ãƒ–ãƒ«çµ±è¨ˆæƒ…å ±
- ãƒ•ã‚¡ã‚¤ãƒ«: \`table_statistics.txt\`
- ãƒ†ãƒ¼ãƒ–ãƒ«ã‚µã‚¤ã‚ºã€æ›´æ–°é »åº¦ã€VACUUMå±¥æ­´

### 8. æœ€é©åŒ–æ¨å¥¨äº‹é …
- ãƒ•ã‚¡ã‚¤ãƒ«: \`optimization_recommendations.md\`
- å…·ä½“çš„ãªæœ€é©åŒ–æ‰‹é †ã¨æ¨å¥¨äº‹é …

## é‡è¦ãªç™ºè¦‹äº‹é …

### ğŸš¨ ç·Šæ€¥å¯¾å¿œãŒå¿…è¦
$(if [ -f "${ANALYSIS_DIR}/performance_monitor_report.txt" ]; then
    if grep -q "dead_tuple_ratio" "${ANALYSIS_DIR}/performance_monitor_report.txt" 2>/dev/null; then
        echo "- ãƒ‡ãƒƒãƒ‰ã‚¿ãƒ—ãƒ«ãŒå¤šã„ãƒ†ãƒ¼ãƒ–ãƒ«ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ"
    fi
    if grep -q "æœªä½¿ç”¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹" "${ANALYSIS_DIR}/index_usage_analysis.txt" 2>/dev/null; then
        echo "- æœªä½¿ç”¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ"
    fi
else
    echo "- è©³ç´°ãªåˆ†æçµæœã‚’ç¢ºèªã—ã¦ãã ã•ã„"
fi)

### âš ï¸ æ³¨æ„ãŒå¿…è¦
- å®Ÿè¡Œæ™‚é–“ã®é•·ã„ã‚¯ã‚¨ãƒªã®ç¢ºèª
- ãƒãƒƒãƒ•ã‚¡ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡ã®æ”¹å–„
- çµ±è¨ˆæƒ…å ±ã®å®šæœŸæ›´æ–°

### âœ… è‰¯å¥½ãªçŠ¶æ…‹
- åŸºæœ¬çš„ãªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹é€ 
- ä¸»è¦ãªã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è¨­å®š

## æ¨å¥¨ã•ã‚Œã‚‹æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³

1. **å³åº§ã«å®Ÿè¡Œ**:
   - \`optimization_recommendations.md\` ã®ç·Šæ€¥å¯¾å¿œé …ç›®ã‚’ç¢ºèª
   - å¿…è¦ã«å¿œã˜ã¦VACUUMå®Ÿè¡Œ

2. **1é€±é–“ä»¥å†…**:
   - æœªä½¿ç”¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®å‰Šé™¤æ¤œè¨
   - ã‚¹ãƒ­ãƒ¼ã‚¯ã‚¨ãƒªã®æœ€é©åŒ–

3. **1ãƒ¶æœˆä»¥å†…**:
   - å®šæœŸãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ã®è‡ªå‹•åŒ–
   - ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ã®å¼·åŒ–

## ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§

\`\`\`
$(ls -la "${ANALYSIS_DIR}" | tail -n +2)
\`\`\`

## å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰

ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã‚’å†ç”Ÿæˆã™ã‚‹ã«ã¯ï¼š

\`\`\`bash
./scripts/run-performance-analysis.sh full
\`\`\`

å€‹åˆ¥åˆ†æã®å®Ÿè¡Œï¼š

\`\`\`bash
# EXPLAIN ANALYZE ã®ã¿
./scripts/explain-analyze-performance-test.sh

# åŸºæœ¬ç›£è¦–ã®ã¿
psql -f ./scripts/postgresql-performance-monitor.sql

# Goç‰ˆåˆ†æã®ã¿
cd scripts && go run query-performance-analyzer.go
\`\`\`

---

**æ³¨æ„**: ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã¯è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸã‚‚ã®ã§ã™ã€‚æœ¬ç•ªç’°å¢ƒã¸ã®å¤‰æ›´é©ç”¨å‰ã«ã¯ã€å¿…ãšè©³ç´°ãªæ¤œè¨¼ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚
EOF
    
    log_success "ç·åˆãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜: ${report_file}"
}

# ãƒ¡ã‚¤ãƒ³å‡¦ç†
main() {
    log_info "=== PostgreSQL ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æé–‹å§‹ ==="
    
    # å¼•æ•°è§£æ
    local analysis_type="${1:-full}"
    
    # å‰ææ¡ä»¶ãƒã‚§ãƒƒã‚¯
    check_prerequisites || exit 1
    
    # çµæœãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    create_results_dir
    
    case "${analysis_type}" in
        "full")
            log_info "å®Œå…¨ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æã‚’å®Ÿè¡Œ..."
            collect_basic_stats
            run_performance_monitor
            run_explain_analyze
            run_go_analyzer
            analyze_index_usage
            analyze_slow_queries
            analyze_table_stats
            generate_optimization_recommendations
            generate_comprehensive_report
            ;;
        "quick")
            log_info "ç°¡æ˜“ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æã‚’å®Ÿè¡Œ..."
            collect_basic_stats
            run_performance_monitor
            analyze_index_usage
            generate_optimization_recommendations
            generate_comprehensive_report
            ;;
        "explain")
            log_info "EXPLAIN ANALYZEåˆ†æã®ã¿å®Ÿè¡Œ..."
            run_explain_analyze
            ;;
        "monitor")
            log_info "ç›£è¦–ãƒ¬ãƒãƒ¼ãƒˆã®ã¿å®Ÿè¡Œ..."
            collect_basic_stats
            run_performance_monitor
            ;;
        "go")
            log_info "Goç‰ˆåˆ†æã®ã¿å®Ÿè¡Œ..."
            run_go_analyzer
            ;;
        "help"|"--help"|"-h")
            echo "ä½¿ç”¨æ–¹æ³•: $0 [analysis_type]"
            echo ""
            echo "Analysis Types:"
            echo "  full     å®Œå…¨ãªåˆ†æå®Ÿè¡Œï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰"
            echo "  quick    ç°¡æ˜“åˆ†æå®Ÿè¡Œ"
            echo "  explain  EXPLAIN ANALYZEåˆ†æã®ã¿"
            echo "  monitor  ç›£è¦–ãƒ¬ãƒãƒ¼ãƒˆã®ã¿"
            echo "  go       Goç‰ˆåˆ†æã®ã¿"
            echo "  help     ãƒ˜ãƒ«ãƒ—è¡¨ç¤º"
            exit 0
            ;;
        *)
            log_error "ä¸æ­£ãªåˆ†æã‚¿ã‚¤ãƒ—: ${analysis_type}"
            log_info "ä½¿ç”¨æ–¹æ³•: $0 [full|quick|explain|monitor|go|help]"
            exit 1
            ;;
    esac
    
    # çµæœè¡¨ç¤º
    echo ""
    log_success "=== ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æå®Œäº† ==="
    log_info "çµæœãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: ${ANALYSIS_DIR}"
    
    if [ -f "${ANALYSIS_DIR}/comprehensive_performance_report.md" ]; then
        log_info "ç·åˆãƒ¬ãƒãƒ¼ãƒˆ: ${ANALYSIS_DIR}/comprehensive_performance_report.md"
    fi
    
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚µã‚¤ã‚ºè¡¨ç¤º
    local dir_size=$(du -sh "${ANALYSIS_DIR}" | cut -f1)
    log_info "åˆ†æçµæœã‚µã‚¤ã‚º: ${dir_size}"
    
    # ãƒ•ã‚¡ã‚¤ãƒ«æ•°è¡¨ç¤º
    local file_count=$(find "${ANALYSIS_DIR}" -type f | wc -l)
    log_info "ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«æ•°: ${file_count}"
}

# ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œ
main "$@"