package main

import (
	"context"
	"database/sql"
	"fmt"
	"log"
	"math/rand"
	"sync"
	"time"

	_ "github.com/lib/pq"
	"go.uber.org/zap"

	"github.com/duesk/monstera/internal/config"
)

// PostgreSQLãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ„ãƒ¼ãƒ«
// ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®åŠ¹æœã‚’æ¸¬å®š

type BenchmarkResult struct {
	TestName     string
	Duration     time.Duration
	Transactions int
	TPS          float64 // Transactions Per Second
	AvgLatency   time.Duration
	MinLatency   time.Duration
	MaxLatency   time.Duration
	Errors       int
}

type MemoryStats struct {
	SharedBufferHitRatio float64
	TempFilesCreated     int64
	TempBytesWritten     int64
}

func main() {
	println("ğŸ§ª PostgreSQL Performance Benchmark")
	println("==================================")
	println("")

	// ãƒ­ã‚¬ãƒ¼åˆæœŸåŒ–
	logger, err := zap.NewDevelopment()
	if err != nil {
		log.Fatalf("Failed to initialize logger: %v", err)
	}
	defer logger.Sync()

	// è¨­å®šèª­ã¿è¾¼ã¿
	cfg, err := config.Load()
	if err != nil {
		logger.Fatal("Failed to load configuration", zap.Error(err))
	}

	// PostgreSQLæ¥ç¶š
	dsn := fmt.Sprintf("host=%s port=%s user=%s password=%s dbname=%s sslmode=disable",
		cfg.Database.Host, cfg.Database.Port, cfg.Database.User,
		cfg.Database.Password, cfg.Database.DBName)

	db, err := sql.Open("postgres", dsn)
	if err != nil {
		logger.Fatal("Failed to connect to database", zap.Error(err))
	}
	defer db.Close()

	// æ¥ç¶šãƒ—ãƒ¼ãƒ«è¨­å®š
	db.SetMaxOpenConns(50)
	db.SetMaxIdleConns(10)
	db.SetConnMaxLifetime(5 * time.Minute)

	// ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
	if err := runBenchmarks(db, logger); err != nil {
		logger.Fatal("Benchmarks failed", zap.Error(err))
	}

	println("")
	println("ğŸ‰ Benchmark completed!")
}

func runBenchmarks(db *sql.DB, logger *zap.Logger) error {
	ctx := context.Background()

	// ãƒ†ã‚¹ãƒˆãƒ†ãƒ¼ãƒ–ãƒ«ã®æº–å‚™
	if err := prepareBenchmarkTables(ctx, db); err != nil {
		return fmt.Errorf("failed to prepare tables: %w", err)
	}

	// ãƒ¡ãƒ¢ãƒªçµ±è¨ˆï¼ˆé–‹å§‹æ™‚ï¼‰
	startMemStats, _ := getMemoryStats(ctx, db)

	// ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
	results := []BenchmarkResult{}

	// 1. å˜ç´”INSERTæ€§èƒ½ãƒ†ã‚¹ãƒˆ
	fmt.Println("1. Simple INSERT Performance Test")
	fmt.Println("=================================")
	result := benchmarkInserts(ctx, db, 10000, 10)
	printResult(result)
	results = append(results, result)
	fmt.Println()

	// 2. è¤‡é›‘ã‚¯ã‚¨ãƒªæ€§èƒ½ãƒ†ã‚¹ãƒˆ
	fmt.Println("2. Complex Query Performance Test")
	fmt.Println("=================================")
	result = benchmarkComplexQueries(ctx, db, 1000, 5)
	printResult(result)
	results = append(results, result)
	fmt.Println()

	// 3. åŒæ™‚å®Ÿè¡Œæ€§èƒ½ãƒ†ã‚¹ãƒˆ
	fmt.Println("3. Concurrent Transaction Test")
	fmt.Println("==============================")
	result = benchmarkConcurrentTransactions(ctx, db, 100, 20)
	printResult(result)
	results = append(results, result)
	fmt.Println()

	// 4. work_memä¾å­˜ã®ã‚½ãƒ¼ãƒˆæ€§èƒ½ãƒ†ã‚¹ãƒˆ
	fmt.Println("4. Sort Performance Test (work_mem)")
	fmt.Println("===================================")
	result = benchmarkSortOperations(ctx, db, 100)
	printResult(result)
	results = append(results, result)
	fmt.Println()

	// 5. ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚¹ã‚­ãƒ£ãƒ³æ€§èƒ½ãƒ†ã‚¹ãƒˆ
	fmt.Println("5. Index Scan Performance Test")
	fmt.Println("==============================")
	result = benchmarkIndexScans(ctx, db, 10000)
	printResult(result)
	results = append(results, result)
	fmt.Println()

	// ãƒ¡ãƒ¢ãƒªçµ±è¨ˆï¼ˆçµ‚äº†æ™‚ï¼‰
	endMemStats, _ := getMemoryStats(ctx, db)

	// ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æƒ…å ±ã‚’è¡¨ç¤º
	fmt.Println("6. Current Parameter Settings")
	fmt.Println("=============================")
	displayCurrentParameters(ctx, db)
	fmt.Println()

	// ãƒ¡ãƒ¢ãƒªä½¿ç”¨çŠ¶æ³
	fmt.Println("7. Memory Usage Statistics")
	fmt.Println("=========================")
	fmt.Printf("Shared Buffer Hit Ratio: %.2f%%\n", endMemStats.SharedBufferHitRatio*100)
	fmt.Printf("Temp Files Created: %d\n", endMemStats.TempFilesCreated-startMemStats.TempFilesCreated)
	fmt.Printf("Temp Bytes Written: %s\n", formatBytes(endMemStats.TempBytesWritten-startMemStats.TempBytesWritten))
	fmt.Println()

	// ã‚µãƒãƒªãƒ¼
	fmt.Println("8. Benchmark Summary")
	fmt.Println("===================")
	var totalTPS float64
	for _, r := range results {
		totalTPS += r.TPS
		fmt.Printf("%-30s: %.2f TPS\n", r.TestName, r.TPS)
	}
	fmt.Printf("\nAverage TPS: %.2f\n", totalTPS/float64(len(results)))

	// ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
	cleanupBenchmarkTables(ctx, db)

	return nil
}

// ãƒ†ã‚¹ãƒˆãƒ†ãƒ¼ãƒ–ãƒ«ã®æº–å‚™
func prepareBenchmarkTables(ctx context.Context, db *sql.DB) error {
	queries := []string{
		`DROP TABLE IF EXISTS bench_data`,
		`CREATE TABLE bench_data (
			id SERIAL PRIMARY KEY,
			uuid_col UUID DEFAULT gen_random_uuid(),
			name TEXT,
			value INTEGER,
			created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
			data JSONB
		)`,
		`CREATE INDEX idx_bench_value ON bench_data(value)`,
		`CREATE INDEX idx_bench_created ON bench_data(created_at)`,
		`CREATE INDEX idx_bench_data_gin ON bench_data USING GIN(data)`,
	}

	for _, query := range queries {
		if _, err := db.ExecContext(ctx, query); err != nil {
			return err
		}
	}

	// åˆæœŸãƒ‡ãƒ¼ã‚¿æŠ•å…¥
	for i := 0; i < 50000; i++ {
		_, err := db.ExecContext(ctx,
			`INSERT INTO bench_data (name, value, data) VALUES ($1, $2, $3)`,
			fmt.Sprintf("record_%d", i),
			rand.Intn(10000),
			fmt.Sprintf(`{"type": "test", "index": %d, "tags": ["tag%d", "tag%d"]}`, i, i%10, i%20),
		)
		if err != nil {
			return err
		}
	}

	return nil
}

// 1. INSERTæ€§èƒ½ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
func benchmarkInserts(ctx context.Context, db *sql.DB, records int, workers int) BenchmarkResult {
	result := BenchmarkResult{
		TestName:     "Simple INSERT",
		Transactions: records,
	}

	latencies := make([]time.Duration, 0, records)
	var mu sync.Mutex
	var wg sync.WaitGroup
	errors := 0

	start := time.Now()
	recordsPerWorker := records / workers

	for w := 0; w < workers; w++ {
		wg.Add(1)
		go func(workerID int) {
			defer wg.Done()

			for i := 0; i < recordsPerWorker; i++ {
				txStart := time.Now()
				_, err := db.ExecContext(ctx,
					`INSERT INTO bench_data (name, value, data) VALUES ($1, $2, $3)`,
					fmt.Sprintf("bench_%d_%d", workerID, i),
					rand.Intn(10000),
					fmt.Sprintf(`{"worker": %d, "index": %d}`, workerID, i),
				)
				latency := time.Since(txStart)

				mu.Lock()
				if err != nil {
					errors++
				} else {
					latencies = append(latencies, latency)
				}
				mu.Unlock()
			}
		}(w)
	}

	wg.Wait()
	result.Duration = time.Since(start)
	result.Errors = errors

	// çµ±è¨ˆè¨ˆç®—
	if len(latencies) > 0 {
		var total time.Duration
		result.MinLatency = latencies[0]
		result.MaxLatency = latencies[0]

		for _, l := range latencies {
			total += l
			if l < result.MinLatency {
				result.MinLatency = l
			}
			if l > result.MaxLatency {
				result.MaxLatency = l
			}
		}

		result.AvgLatency = total / time.Duration(len(latencies))
		result.TPS = float64(len(latencies)) / result.Duration.Seconds()
	}

	return result
}

// 2. è¤‡é›‘ã‚¯ã‚¨ãƒªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
func benchmarkComplexQueries(ctx context.Context, db *sql.DB, queries int, workers int) BenchmarkResult {
	result := BenchmarkResult{
		TestName:     "Complex Query",
		Transactions: queries,
	}

	latencies := make([]time.Duration, 0, queries)
	var mu sync.Mutex
	var wg sync.WaitGroup
	errors := 0

	start := time.Now()
	queriesPerWorker := queries / workers

	for w := 0; w < workers; w++ {
		wg.Add(1)
		go func() {
			defer wg.Done()

			for i := 0; i < queriesPerWorker; i++ {
				txStart := time.Now()

				// è¤‡é›‘ãªã‚¯ã‚¨ãƒªï¼ˆé›†è¨ˆã€JOINç›¸å½“ã®å‡¦ç†ï¼‰
				var count int
				err := db.QueryRowContext(ctx, `
					WITH aggregated AS (
						SELECT 
							value / 100 as bucket,
							COUNT(*) as cnt,
							AVG(value) as avg_value,
							MAX(created_at) as latest
						FROM bench_data
						WHERE value BETWEEN $1 AND $2
						GROUP BY value / 100
					)
					SELECT COUNT(*) FROM aggregated WHERE cnt > 10
				`, rand.Intn(5000), rand.Intn(5000)+5000).Scan(&count)

				latency := time.Since(txStart)

				mu.Lock()
				if err != nil {
					errors++
				} else {
					latencies = append(latencies, latency)
				}
				mu.Unlock()
			}
		}()
	}

	wg.Wait()
	result.Duration = time.Since(start)
	result.Errors = errors

	// çµ±è¨ˆè¨ˆç®—
	calculateStats(&result, latencies)
	return result
}

// 3. åŒæ™‚å®Ÿè¡Œãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
func benchmarkConcurrentTransactions(ctx context.Context, db *sql.DB, txPerWorker int, workers int) BenchmarkResult {
	result := BenchmarkResult{
		TestName:     "Concurrent Transactions",
		Transactions: txPerWorker * workers,
	}

	latencies := make([]time.Duration, 0, txPerWorker*workers)
	var mu sync.Mutex
	var wg sync.WaitGroup
	errors := 0

	start := time.Now()

	for w := 0; w < workers; w++ {
		wg.Add(1)
		go func(workerID int) {
			defer wg.Done()

			for i := 0; i < txPerWorker; i++ {
				txStart := time.Now()

				tx, err := db.BeginTx(ctx, nil)
				if err != nil {
					mu.Lock()
					errors++
					mu.Unlock()
					continue
				}

				// ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³å†…ã§è¤‡æ•°æ“ä½œ
				success := true
				for j := 0; j < 5; j++ {
					_, err = tx.ExecContext(ctx,
						`UPDATE bench_data SET value = value + 1 WHERE id = $1`,
						rand.Intn(10000)+1,
					)
					if err != nil {
						success = false
						break
					}
				}

				if success {
					err = tx.Commit()
				} else {
					err = tx.Rollback()
				}

				latency := time.Since(txStart)

				mu.Lock()
				if err != nil {
					errors++
				} else {
					latencies = append(latencies, latency)
				}
				mu.Unlock()
			}
		}(w)
	}

	wg.Wait()
	result.Duration = time.Since(start)
	result.Errors = errors

	calculateStats(&result, latencies)
	return result
}

// 4. ã‚½ãƒ¼ãƒˆæ€§èƒ½ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ï¼ˆwork_memãƒ†ã‚¹ãƒˆï¼‰
func benchmarkSortOperations(ctx context.Context, db *sql.DB, iterations int) BenchmarkResult {
	result := BenchmarkResult{
		TestName:     "Sort Operations",
		Transactions: iterations,
	}

	latencies := make([]time.Duration, 0, iterations)
	errors := 0

	start := time.Now()

	for i := 0; i < iterations; i++ {
		txStart := time.Now()

		// å¤§é‡ãƒ‡ãƒ¼ã‚¿ã®ã‚½ãƒ¼ãƒˆ
		rows, err := db.QueryContext(ctx, `
			SELECT name, value, data
			FROM bench_data
			ORDER BY value DESC, created_at DESC
			LIMIT 1000
		`)

		if err == nil {
			// çµæœã‚’èª­ã¿è¾¼ã‚€
			for rows.Next() {
				var name string
				var value int
				var data string
				rows.Scan(&name, &value, &data)
			}
			rows.Close()
		}

		latency := time.Since(txStart)

		if err != nil {
			errors++
		} else {
			latencies = append(latencies, latency)
		}
	}

	result.Duration = time.Since(start)
	result.Errors = errors

	calculateStats(&result, latencies)
	return result
}

// 5. ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚¹ã‚­ãƒ£ãƒ³æ€§èƒ½ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
func benchmarkIndexScans(ctx context.Context, db *sql.DB, scans int) BenchmarkResult {
	result := BenchmarkResult{
		TestName:     "Index Scans",
		Transactions: scans,
	}

	latencies := make([]time.Duration, 0, scans)
	errors := 0

	start := time.Now()

	for i := 0; i < scans; i++ {
		txStart := time.Now()

		// ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½¿ç”¨ã™ã‚‹ã‚¯ã‚¨ãƒª
		var count int
		err := db.QueryRowContext(ctx, `
			SELECT COUNT(*)
			FROM bench_data
			WHERE value BETWEEN $1 AND $2
			  AND data @> '{"type": "test"}'::jsonb
		`, rand.Intn(8000), rand.Intn(2000)+8000).Scan(&count)

		latency := time.Since(txStart)

		if err != nil {
			errors++
		} else {
			latencies = append(latencies, latency)
		}
	}

	result.Duration = time.Since(start)
	result.Errors = errors

	calculateStats(&result, latencies)
	return result
}

// çµ±è¨ˆè¨ˆç®—ãƒ˜ãƒ«ãƒ‘ãƒ¼
func calculateStats(result *BenchmarkResult, latencies []time.Duration) {
	if len(latencies) > 0 {
		var total time.Duration
		result.MinLatency = latencies[0]
		result.MaxLatency = latencies[0]

		for _, l := range latencies {
			total += l
			if l < result.MinLatency {
				result.MinLatency = l
			}
			if l > result.MaxLatency {
				result.MaxLatency = l
			}
		}

		result.AvgLatency = total / time.Duration(len(latencies))
		result.TPS = float64(len(latencies)) / result.Duration.Seconds()
	}
}

// ç¾åœ¨ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šã‚’è¡¨ç¤º
func displayCurrentParameters(ctx context.Context, db *sql.DB) {
	params := []string{
		"shared_buffers",
		"effective_cache_size",
		"work_mem",
		"maintenance_work_mem",
		"max_connections",
		"random_page_cost",
		"effective_io_concurrency",
	}

	for _, param := range params {
		var value string
		err := db.QueryRowContext(ctx, "SHOW "+param).Scan(&value)
		if err == nil {
			fmt.Printf("%-25s: %s\n", param, value)
		}
	}
}

// ãƒ¡ãƒ¢ãƒªçµ±è¨ˆã‚’å–å¾—
func getMemoryStats(ctx context.Context, db *sql.DB) (MemoryStats, error) {
	var stats MemoryStats

	// å…±æœ‰ãƒãƒƒãƒ•ã‚¡ãƒ’ãƒƒãƒˆç‡
	err := db.QueryRowContext(ctx, `
		SELECT 
			CASE 
				WHEN sum(heap_blks_hit) + sum(heap_blks_read) = 0 THEN 0
				ELSE sum(heap_blks_hit)::float / (sum(heap_blks_hit) + sum(heap_blks_read))
			END as hit_ratio
		FROM pg_statio_user_tables
	`).Scan(&stats.SharedBufferHitRatio)
	if err != nil {
		return stats, err
	}

	// ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«çµ±è¨ˆ
	err = db.QueryRowContext(ctx, `
		SELECT 
			COALESCE(sum(temp_files), 0),
			COALESCE(sum(temp_bytes), 0)
		FROM pg_stat_database
		WHERE datname = current_database()
	`).Scan(&stats.TempFilesCreated, &stats.TempBytesWritten)

	return stats, err
}

// çµæœã‚’è¡¨ç¤º
func printResult(result BenchmarkResult) {
	fmt.Printf("Transactions: %d\n", result.Transactions)
	fmt.Printf("Duration: %v\n", result.Duration)
	fmt.Printf("TPS: %.2f\n", result.TPS)
	fmt.Printf("Avg Latency: %v\n", result.AvgLatency)
	fmt.Printf("Min Latency: %v\n", result.MinLatency)
	fmt.Printf("Max Latency: %v\n", result.MaxLatency)
	fmt.Printf("Errors: %d\n", result.Errors)
}

// ãƒã‚¤ãƒˆæ•°ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
func formatBytes(bytes int64) string {
	const unit = 1024
	if bytes < unit {
		return fmt.Sprintf("%d B", bytes)
	}
	div, exp := int64(unit), 0
	for n := bytes / unit; n >= unit; n /= unit {
		div *= unit
		exp++
	}
	return fmt.Sprintf("%.1f %cB", float64(bytes)/float64(div), "KMGTPE"[exp])
}

// ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
func cleanupBenchmarkTables(ctx context.Context, db *sql.DB) {
	db.ExecContext(ctx, "DROP TABLE IF EXISTS bench_data")
}
